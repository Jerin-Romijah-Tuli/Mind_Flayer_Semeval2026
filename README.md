# ğŸ§  Mind_Flayer at SemEval-2026 Task 8B

<div align="center">

[![SemEval 2026](https://img.shields.io/badge/SemEval-2026-blue)](https://semeval.github.io/)
[![Task 8B](https://img.shields.io/badge/Task-8B%20MTRAGEval-orange)](https://github.com/semeval2026/task8)
[![Rank](https://img.shields.io/badge/Rank-8%2F26-brightgreen)](https://github.com/JerinTuli/mind-flayer-semeval2026)
[![F1 Score](https://img.shields.io/badge/F1-0.7492-success)](https://github.com/JerinTuli/mind-flayer-semeval2026)
[![Paper](https://img.shields.io/badge/Paper-arXiv-red)](https://arxiv.org/abs/XXXX.XXXXX)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

**Zero-Shot Multi-Turn RAG with Differential Prompting and Multi-Key Orchestration**

*Achieving Top 31% Performance with $0 Cost and Zero Training*

[ğŸ“„ Paper](#paper) â€¢ [ğŸš€ Quick Start](#quick-start) â€¢ [ğŸ’¡ Key Features](#key-features) â€¢ [ğŸ“Š Results](#results) â€¢ [ğŸ› ï¸ Installation](#installation) â€¢ [ğŸ“– Documentation](#documentation)

</div>

---

## ğŸ† Achievements

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥ˆ Rank 8/26 Teams (Top 31%)                            â”‚
â”‚  ğŸ“ˆ F1 Score: 0.7492                                     â”‚
â”‚  ğŸ¯ ROUGE-L: 0.8782 (Exceptional!)                       â”‚
â”‚  ğŸ¤– LLM Judge: 0.8297 (Excellent!)                       â”‚
â”‚  âœ… Answerability: 100% Accuracy                         â”‚
â”‚  ğŸ’° Cost: $0 (Free Groq API)                             â”‚
â”‚  âš¡ Processing: 21 minutes for 507 tasks                â”‚
â”‚  ğŸ“¦ Model Size: 17B (7Ã— smaller than baseline)          â”‚
â”‚  ğŸ”¥ Beat GPT-OSS-120B by +0.11 F1                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Overview

**Mind_Flayer** is a zero-shot multi-turn Retrieval-Augmented Generation (RAG) system designed for SemEval-2026 Task 8B. We demonstrate that careful prompt engineering and smart system design can achieve **competitive results without training or expensive compute**.

### ğŸŒŸ What Makes This Special?

- **ğŸ¨ Differential Prompting**: Distinct templates for answerable vs unanswerable questions
- **ğŸ”„ Multi-Key API Rotation**: Smart orchestration handles rate limits seamlessly
- **ğŸ›¡ï¸ Post-Processing Safety Net**: Corrects model failures before submission
- **ğŸ’¯ Perfect Answerability**: 100% accuracy on question answerable classification
- **ğŸ’¸ Zero Cost**: Built entirely on free-tier APIs
- **ğŸ“š No Training**: Pure zero-shot approach - works out of the box

---

## ğŸ’¡ Key Features

### 1ï¸âƒ£ **Explicit Answerability Detection**

```python
def check_answerability(task):
    """
    Simple but perfect: 100% accuracy on 507 tasks
    """
    contexts = task.get('contexts', [])
    return UNANSWERABLE if len(contexts) == 0 else ANSWERABLE
```

**Why it works:** Leverages the explicit data structure where unanswerable questions have zero passages.

### 2ï¸âƒ£ **Differential Prompting**

<table>
<tr>
<td width="50%">

**Answerable Template** ğŸŸ¢
```
You MUST answer using reference 
information...

âœ“ Explicit grounding
âœ“ 2-4 sentence constraint
âœ“ Multi-turn awareness
âœ“ Domain-specific guidance
âœ“ Temperature: 0.3
```

</td>
<td width="50%">

**Unanswerable Template** ğŸ”´
```
You do NOT have any information...
You MUST politely decline...

âœ“ Strong negatives
âœ“ Refusal examples
âœ“ Prohibition on answering
âœ“ Lower temperature: 0.1
```

</td>
</tr>
</table>

### 3ï¸âƒ£ **Multi-Key API Rotation**

```python
class MultiKeyGenerator:
    """
    Seamlessly handles API rate limits
    Processes 507 tasks in 21 minutes with $0 cost
    """
    def __init__(self, api_keys):
        self.clients = [Groq(key) for key in api_keys]
        self.current_idx = 0
        self.exhausted = set()
    
    def handle_rate_limit(self, error):
        if "TPD" in str(error):  # Token Per Day limit
            self.exhausted.add(self.current_idx)
            self.rotate()
```

**Impact:** Enables processing of large datasets without hitting free-tier limits.

### 4ï¸âƒ£ **Post-Processing Safety Net**

```python
def post_process(response, has_contexts):
    """
    Corrects ~6% of responses
    Contributes +0.029 to F1 score
    """
    # Detect incorrect response type
    is_refusal = any(kw in response.lower() 
                    for kw in ["don't have", "cannot answer"])
    
    # Fix mismatches
    if has_contexts and is_refusal:
        return "Based on available information..."
    if not has_contexts and not is_refusal:
        return "I don't have information needed..."
    
    return response
```

**Why it matters:** Even with perfect prompts, LLMs occasionally fail. This catches edge cases.

---

## ğŸ“Š Results

### ğŸ–ï¸ Official Leaderboard

| System | Overall F1 | ROUGE-L | LLM Judge | Rank |
|--------|------------|---------|-----------|------|
| **Mind_Flayer (Ours)** | **0.7492** | **0.8782** | **0.8297** | **8/26** |
| Top System | 0.7827 | -- | -- | 1/26 |
| GPT-OSS-120B | 0.639 | -- | -- | baseline |
| GPT-4o | 0.60 | -- | -- | baseline |

### ğŸ“ˆ Component Contributions

```
Full System                    0.7492  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
- Multi-turn Context          -0.0504  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              (largest impact)
- Post-processing            -0.0291  â–ˆâ–ˆâ–ˆâ–ˆ
- Domain Guidance            -0.0137  â–ˆâ–ˆ
Simple Baseline               0.6532  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

### ğŸ¯ Answerability Performance

| Type | Count | Accuracy |
|------|-------|----------|
| Answerable | 377 | **100%** âœ… |
| Unanswerable | 130 | **100%** âœ… |
| **Overall** | **507** | **100%** âœ… |

### ğŸŒ Domain Performance (ROUGE-L)

```
CLAPNQ (Wikipedia)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.89
Govt (Government)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.88
Cloud (Technical)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   0.87
FiQA (Financial)      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    0.85
```

### ğŸ“Š Turn-wise Analysis

- **Turn 1**: 0.94 RL_F (Strong initial responses)
- **Turn >1**: 0.86 RL_F (Multi-turn complexity evident)

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8+
python --version

# Install dependencies
pip install groq python-dotenv tqdm
```

### âš¡ 30-Second Setup

```bash
# 1. Clone repository
git clone https://github.com/JerinTuli/mind-flayer-semeval2026.git
cd mind-flayer-semeval2026

# 2. Set up environment
cp .env.example .env
# Add your Groq API keys to .env

# 3. Run inference
python run_inference.py \
    --input_file data/test_tasks.jsonl \
    --output_file predictions.jsonl \
    --model meta-llama/llama-4-scout-17b-16e-instruct
```

**That's it!** ğŸ‰

---

## ğŸ› ï¸ Installation

### Option 1: Basic Installation

```bash
pip install -r requirements.txt
```

### Option 2: Development Installation

```bash
# Clone with submodules
git clone --recursive https://github.com/JerinTuli/mind-flayer-semeval2026.git

# Install in editable mode
pip install -e .

# Install dev dependencies
pip install -r requirements-dev.txt
```

### ğŸ“‹ Requirements

```txt
groq>=0.9.0
python-dotenv>=1.0.0
tqdm>=4.66.0
```

---

## ğŸ’» Usage

### Basic Usage

```python
from mind_flayer import MindFlayerRAG

# Initialize system
rag = MindFlayerRAG(
    api_keys=["your-groq-key-1", "your-groq-key-2"],
    model="meta-llama/llama-4-scout-17b-16e-instruct"
)

# Process single task
task = {
    "conversation": [...],
    "contexts": [...],
    "question": "What is the capital of France?"
}

response = rag.generate(task)
print(response)
# Output: "Based on the provided information, Paris is the capital of France."
```

### Batch Processing

```python
from mind_flayer import batch_process

# Process entire dataset
results = batch_process(
    input_file="data/test_tasks.jsonl",
    output_file="predictions.jsonl",
    api_keys=["key1", "key2"],
    batch_size=32
)

print(f"Processed {results['total']} tasks")
print(f"Success rate: {results['success_rate']:.2%}")
```

### Custom Configuration

```python
rag = MindFlayerRAG(
    api_keys=api_keys,
    model="meta-llama/llama-4-scout-17b-16e-instruct",
    temperature_answerable=0.3,
    temperature_unanswerable=0.1,
    max_tokens=512,
    enable_post_processing=True,
    enable_domain_guidance=True
)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       INPUT TASK                            â”‚
â”‚  â€¢ Conversation History (1-11 turns, mean: 7.64)            â”‚
â”‚  â€¢ Reference Passages (0-38, mean: 2.33 for answerable)    â”‚
â”‚  â€¢ Domain (fiqa, cloud, govt, clapnq)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STAGE 1: ANSWERABILITY CHECK                    â”‚
â”‚                len(contexts) == 0?                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                        â”‚
         NO (377)                  YES (130)
               â”‚                        â”‚
               â–¼                        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   ANSWERABLE        â”‚  â”‚   UNANSWERABLE      â”‚
   â”‚   Template          â”‚  â”‚   Template          â”‚
   â”‚   â€¢ Strict ground   â”‚  â”‚   â€¢ Polite refuse   â”‚
   â”‚   â€¢ 2-4 sentences   â”‚  â”‚   â€¢ No speculation  â”‚
   â”‚   â€¢ T=0.3           â”‚  â”‚   â€¢ T=0.1           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   STAGE 2: MULTI-KEY ROTATION   â”‚
           â”‚   â€¢ Groq API (free tier)        â”‚
           â”‚   â€¢ Automatic failover          â”‚
           â”‚   â€¢ 2 keys, 21 minutes, $0     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   STAGE 3: POST-PROCESSING      â”‚
           â”‚   â€¢ Detect mismatches           â”‚
           â”‚   â€¢ Correct ~6% responses       â”‚
           â”‚   â€¢ Ensure consistency          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚        FINAL RESPONSE            â”‚
           â”‚   â€¢ Grounded (if answerable)    â”‚
           â”‚   â€¢ Refusal (if unanswerable)   â”‚
           â”‚   â€¢ Multi-turn coherent         â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Documentation

### ğŸ“ Project Structure

```
mind-flayer-semeval2026/
â”œâ”€â”€ ğŸ“„ README.md                    # You are here!
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencies
â”œâ”€â”€ ğŸ“„ .env.example                 # Environment template
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mind_flayer.py             # Main RAG system
â”‚   â”œâ”€â”€ prompts.py                 # Prompt templates
â”‚   â”œâ”€â”€ multi_key.py               # API key rotation
â”‚   â”œâ”€â”€ post_process.py            # Safety net logic
â”‚   â””â”€â”€ utils.py                   # Helper functions
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ train/                     # Training data (if any)
â”‚   â”œâ”€â”€ dev/                       # Development set
â”‚   â””â”€â”€ test/                      # Test set
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ exploration.ipynb          # Data analysis
â”‚   â”œâ”€â”€ error_analysis.ipynb       # Error analysis
â”‚   â””â”€â”€ visualization.ipynb        # Result visualization
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â”œâ”€â”€ run_inference.py           # Main inference script
â”‚   â”œâ”€â”€ evaluate.py                # Evaluation script
â”‚   â””â”€â”€ format_checker.py          # Output validation
â”‚
â”œâ”€â”€ ğŸ“‚ results/
â”‚   â”œâ”€â”€ predictions.jsonl          # System outputs
â”‚   â”œâ”€â”€ metrics.json               # Evaluation metrics
â”‚   â””â”€â”€ analysis/                  # Detailed analysis
â”‚
â”œâ”€â”€ ğŸ“‚ paper/
â”‚   â”œâ”€â”€ semeval_2026_paper.pdf     # Final paper
â”‚   â””â”€â”€ semeval_2026_paper.tex     # LaTeX source
â”‚
â””â”€â”€ ğŸ“‚ tests/
    â”œâ”€â”€ test_answerability.py
    â”œâ”€â”€ test_prompts.py
    â”œâ”€â”€ test_multi_key.py
    â””â”€â”€ test_post_process.py
```

### ğŸ”‘ Configuration

Create `.env` file:

```bash
# Groq API Keys (get free keys at https://console.groq.com)
GROQ_API_KEY_1=gsk_...
GROQ_API_KEY_2=gsk_...

# Model Configuration
MODEL_NAME=meta-llama/llama-4-scout-17b-16e-instruct
TEMPERATURE_ANSWERABLE=0.3
TEMPERATURE_UNANSWERABLE=0.1
MAX_TOKENS=512

# System Configuration
ENABLE_POST_PROCESSING=true
ENABLE_DOMAIN_GUIDANCE=true
BATCH_SIZE=32
```

### ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_answerability.py -v

# Run with coverage
pytest --cov=src tests/
```

---

## ğŸ“ Detailed Examples

### Example 1: Answerable Question

**Input:**
```json
{
  "conversation": [
    {"role": "user", "content": "What is Paris?"},
    {"role": "assistant", "content": "Paris is the capital of France."},
    {"role": "user", "content": "What's its population?"}
  ],
  "contexts": [
    {
      "text": "As of 2024, Paris has a population of approximately 2.1 million...",
      "document_id": "wiki_paris_001",
      "score": 0.95
    }
  ]
}
```

**Output:**
```
"According to the provided information, Paris has a population of 
approximately 2.1 million as of 2024."
```

**Analysis:** âœ… Grounded, âœ… Multi-turn coherent, âœ… Concise (2 sentences)

### Example 2: Unanswerable Question

**Input:**
```json
{
  "conversation": [
    {"role": "user", "content": "What is the weather in Tokyo tomorrow?"}
  ],
  "contexts": []
}
```

**Output:**
```
"I don't have the information needed to answer that question."
```

**Analysis:** âœ… Polite refusal, âœ… No hallucination, âœ… IDK judge compatible

### Example 3: Multi-turn with Follow-up

**Input:**
```json
{
  "conversation": [
    {"role": "user", "content": "What is machine learning?"},
    {"role": "assistant", "content": "Machine learning is..."},
    {"role": "user", "content": "What are its main types?"}
  ],
  "contexts": [
    {"text": "The three main types are supervised, unsupervised, and reinforcement learning..."}
  ]
}
```

**Output:**
```
"Building on the previous discussion, the three main types are 
supervised learning, unsupervised learning, and reinforcement learning."
```

**Analysis:** âœ… References previous context, âœ… Grounded, âœ… Natural flow

---

## ğŸ”¬ Analysis & Insights

### ğŸ’ª Strengths

1. **Exceptional Faithfulness (0.8782 ROUGE-L)**
   - Accurate information extraction
   - Strong passage grounding
   - Appropriate response length

2. **Perfect Answerability (100%)**
   - Zero false positives (no hallucinations on unanswerable)
   - Zero false negatives (no refusals on answerable)

3. **Resource Efficiency**
   - $0 cost (vs potentially $100+ for GPT-4 API)
   - 7Ã— smaller model (17B vs 120B)
   - 21 minutes for 507 tasks

4. **Accessibility**
   - No GPUs needed
   - No training required
   - Fully reproducible with free APIs

### ğŸ¯ Areas for Improvement

1. **Completeness (RB_agg: 0.6024)**
   - Trade-off from 2-4 sentence constraint
   - Could benefit from adaptive length
   - Multi-passage synthesis can improve

2. **Later-Turn Performance**
   - Turn 1: 0.94 RL_F
   - Turn >1: 0.86 RL_F
   - Room for better context integration

3. **Domain Adaptation**
   - FiQA (0.85) lower than others (0.87-0.89)
   - Informal forum style harder to match

### ğŸš€ Future Work

- [ ] Adaptive response length based on query complexity
- [ ] Multi-stage generation (outline â†’ elaborate)
- [ ] Ensemble approaches for improved completeness
- [ ] Better multi-passage synthesis
- [ ] Integration with retrieval (Task C)
- [ ] Testing with larger models (Llama 3.1 70B/405B)

---

## ğŸ“š Citation

If you use this code or find our work helpful, please cite:

```bibtex
@inproceedings{tuli2026mindflayer,
  title={Mind\_Flayer at SemEval-2026 Task 8: Faithful Multi-Turn RAG Generation via Llama-4-Scout and Smart API Key Rotation},
  author={Tuli, Jerin Romijah and Pritom, MD. Sartaj Alam and Naem, Talukder Naemul Hasan},
  booktitle={Proceedings of the 20th International Workshop on Semantic Evaluation (SemEval-2026)},
  year={2026},
  organization={Association for Computational Linguistics}
}
```

**Paper:** [arXiv:XXXX.XXXXX](https://arxiv.org/abs/XXXX.XXXXX) (Update after publication)

---

## ğŸ‘¥ Team

<table>
  <tr>
    <td align="center">
      <img src="https://github.com/JerinTuli.png" width="100px;" alt="Jerin"/><br />
      <sub><b>Jerin Romijah Tuli</b></sub><br />
      <a href="mailto:ramijahtuli786@gmail.com">ğŸ“§ Email</a>
    </td>
    <td align="center">
      <img src="https://via.placeholder.com/100" width="100px;" alt="Sartaj"/><br />
      <sub><b>MD. Sartaj Alam Pritom</b></sub><br />
      <a href="mailto:sartajalam0010@gmail.com">ğŸ“§ Email</a>
    </td>
    <td align="center">
      <img src="https://via.placeholder.com/100" width="100px;" alt="Naem"/><br />
      <sub><b>Talukder Naemul Hasan Naem</b></sub><br />
      <a href="mailto:naemruet@gmail.com">ğŸ“§ Email</a>
    </td>
  </tr>
</table>

**Institution:** Department of Computer Science and Engineering  
**University:** Rajshahi University of Engineering & Technology, Bangladesh

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md).

```bash
# Fork the repository
# Create your feature branch
git checkout -b feature/AmazingFeature

# Commit your changes
git commit -m 'Add some AmazingFeature'

# Push to the branch
git push origin feature/AmazingFeature

# Open a Pull Request
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2026 Mind_Flayer Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ™ Acknowledgments

- **SemEval-2026 Organizers** - Sara Rosenthal, Yannis Katsis, Vraj Shah, Marina Danilevsky
- **Groq** - For providing free API access to Llama 4 Scout 17B
- **Meta AI** - For the Llama model family
- **MTRAG Benchmark Team** - For the comprehensive evaluation dataset

---

## ğŸ“ Contact & Support

- **Issues:** [GitHub Issues](https://github.com/JerinTuli/mind-flayer-semeval2026/issues)
- **Discussions:** [GitHub Discussions](https://github.com/JerinTuli/mind-flayer-semeval2026/discussions)
- **Email:** ramijahtuli786@gmail.com

---

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=JerinTuli/mind-flayer-semeval2026&type=Date)](https://star-history.com/#JerinTuli/mind-flayer-semeval2026&Date)

---

<div align="center">

### ğŸ’« Made with â¤ï¸ by Team Mind_Flayer

**If you found this useful, please consider giving us a â­!**

[![GitHub stars](https://img.shields.io/github/stars/JerinTuli/mind-flayer-semeval2026?style=social)](https://github.com/JerinTuli/mind-flayer-semeval2026/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/JerinTuli/mind-flayer-semeval2026?style=social)](https://github.com/JerinTuli/mind-flayer-semeval2026/network/members)
[![GitHub watchers](https://img.shields.io/github/watchers/JerinTuli/mind-flayer-semeval2026?style=social)](https://github.com/JerinTuli/mind-flayer-semeval2026/watchers)

</div>
